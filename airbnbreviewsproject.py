# -*- coding: utf-8 -*-
"""AirbnbReviewsProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bsyxx7oDky5pMn6W3Mz6dL7dQSn6t3KY
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from bs4 import BeautifulSoup
import torch
import tensorflow as tf
from tensorflow.keras.layers import *
from transformers import BertTokenizer, BertModel, pipeline
from sklearn.feature_extraction.text import TfidfVectorizer

df = pd.read_csv("reviews.csv")
df.head()

df.info()

df['comments'].fillna('', inplace=True)

df.shape

df = df.iloc[:100, :]

nltk.download('stopwords')
nltk.download('punkt_tab')
stp = set(stopwords.words('english'))

df['date'] = pd.to_datetime(df['date'])

def cleaning(text) :
  text = BeautifulSoup(text, 'html.parser').get_text()
  text = text.lower()
  tokens = word_tokenize(text)
  tokens = [word for word in tokens if word.isalpha() and word not in stp]
  return ' '.join(tokens)

df['clean_comments'] = df['comments'].apply(cleaning)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

"""__Fine tuned BERT Model__"""

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertModel.from_pretrained('bert-base-uncased')

def embedding(text) :
  tokens = tokenizer(text, padding=True, truncation=True, max_length = 512, return_tensors = 'pt')
  tokens = {key : value.to(device) for key, value in tokens.items()}
  with torch.no_grad() :
    op = model(**tokens)
  return op.last_hidden_state.mean(1).cpu().squeeze().numpy()

df['embeddings'] = df['clean_comments'].apply(embedding)
df[['embeddings']].head()

# cant add any ann as there is no labels provided !!!

"""__Pretrained PIPELINE__"""

sent_analyzer = pipeline('sentiment-analysis', device = 0 if torch.cuda.is_available() else -1)

def analyze(text) :
  result = sent_analyzer(text)[0]
  return result['label'], result['score']

df[['sentiment_label', 'sentiment_score']] = df['clean_comments'].apply(lambda x : pd.Series(analyze(x)))
df[['comments', 'sentiment_label', 'sentiment_score']].head()

"""__Text Summarization using t5-small and bart model__"""

# summarizer = pipeline('summarization', model = 'facebook/bart-large-cnn')
summarizer = pipeline('summarization', model = 't5-small', device = 0 if torch.cuda.is_available() else -1)
def summarize(text) :
  if len(text.split()) > 50 :
    summary = summarizer(text, max_length = 51, min_length = 25, do_sample = False)[0]['summary_text']
  else :
    summary = text
  return summary

df['summary'] = df['comments'].apply(summarize)
df[['comments', 'summary']].head()

"""__Topic Identification__"""

tfidf = TfidfVectorizer(max_features = 1000)
matrix = tfidf.fit_transform(df['clean_comments'])
features = tfidf.get_feature_names_out()

def keywords(row, n = 10) :
  top_indexes = row.toarray()[0].argsort()[::-1]
  top_indexes = top_indexes[:n]
  topics = [features[i] for i in top_indexes]
  return topics

#df['topics'] = pd.DataFrame(matrix.toarray()).apply(keywords, axis = 1)
df['topics'] = [keywords(r) for r in matrix]
df[['comments', 'topics']].head()

sns.countplot(data = df, x = 'sentiment_label')
plt.show()

from wordcloud import WordCloud
text = ' '.join(df['clean_comments'])
wordcloud = WordCloud(width = 1000, height = 800, background_color = 'white').generate(text)
plt.imshow(wordcloud)
plt.axis('off')
plt.show()

print("Review: ", df['comments'][0], '\n')
print("Cleaned Review: ", df['clean_comments'][0], '\n')
print("Sentiment Label: ", df['sentiment_label'][0], '\n')
print("Sentiment Score: ", df['sentiment_score'][0], '\n')
print("Summary: ", df['summary'][0], '\n')
print("Topics: ", df['topics'][0], '\n')